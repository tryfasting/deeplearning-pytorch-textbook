{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN의 입출력 단위가 단어 레벨(word-level)이 아니라 문자 레벨(character-level)로 하여 RNN을 구현한다면, 이를 문자 단위 RNN이라고 한다. 다대다 구조로 구현해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문자 단위 RNN(Char RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 훈련 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터와 레이블 데이터에 대해서 문자 집합(vocabulary)를 만든다.  \n",
    "여기서 문자 집합은 중복을 제거한 문자들의 집합이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 5\n"
     ]
    }
   ],
   "source": [
    "input_str = 'apple'\n",
    "label_str = 'pple!'\n",
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "vocab_size = len(char_vocab)\n",
    "print(f'문자 집합의 크기 : {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합의 문자는 총 5개이다. '!,a,e,l,p'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 하이퍼파라미터를 정의한다.  \n",
    "입력은 원-핫 벡터를 사용할 것이므로 입력의 크기는 문자 집합의 크기여야만 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size # 입력의 크기는 문자 집합의 크기\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합에 고유한 정수를 부여한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c,i) for i,c in enumerate(char_vocab))\n",
    "# 문자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나중에 예측 결과를 다시 문자 시퀀스로 보기 위해서   \n",
    "반대로 정수로부터 문자를 얻을 수 있는 index_to_char를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key\n",
    "\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 입력 데이터와 레이블 데이터의 각 문자들을 정수로 맵핑한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 nn.RNN()은 기본적으로 3차원 텐서를 입력받는다.  \n",
    "따라서 배치 차원을 추가해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4, 3, 2]]\n",
      "[[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 배치 차원 추가\n",
    "# 텐서 연산인 unsqueeze(0)를 통해 해결할 수도 있음.\n",
    "x_data = [x_data]\n",
    "y_data = [y_data]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 시퀀스의 각 문자들을 원-핫 벡터로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터와 레이블 데이터를 텐서로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 각 텐서의 크기를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : torch.Size([1, 5, 5])\n",
      "레이블의 크기 : torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'훈련 데이터의 크기 : {X.shape}')\n",
    "print(f'레이블의 크기 : {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 RNN 모델을 구현하자.  \n",
    "fc는 fully-connected layer를 뜻하며, 출력층으로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size,hidden_size,batch_first=True) # RNN 셀 구현\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size, bias=True) # 출력층 구현\n",
    "\n",
    "    def forward(self, x): # 구현한 RNN 셀과 출력층을 연결\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스로 정의한 모델을 net에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 입력된 모델에 입력을 넣어서 출력의 크기를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1,5,5)의 크기를 갖는데, 각각  \n",
    "배치 차원,  \n",
    "시점,  \n",
    "출력의 크기   \n",
    "이다. 나중에 정확도를 측정할 때는 이를 모두 펼쳐서 계산하게 되는데,  \n",
    "이때는 view를 사용하여 배치 차원과 시점 차원을 하나로 만든다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.view(-1, input_size).shape) # 2차원 텐서로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 레이블 데이터의 크기를 리마인드 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(Y.view(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 데이터는 (1,5)의 크기를 가지는데,   \n",
    "마찬가지로 나중에 정확도를 측정할 때는 이를 펼쳐서 계산할 예정이다.   \n",
    "이 경우 (5)의 크기를 가지게 된다.  \n",
    "\n",
    "이제 옵티마이저와 손실 함수를 정의한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss : 0.00020904606208205223\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "1 loss : 0.0002084262960124761\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "2 loss : 0.0002078065590467304\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "3 loss : 0.0002072344796033576\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "4 loss : 0.00020663856412284076\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "5 loss : 0.00020604263409040868\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "6 loss : 0.0002053990465356037\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "7 loss : 0.00020485080312937498\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "8 loss : 0.00020427870913408697\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "9 loss : 0.00020365897216834128\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "10 loss : 0.00020308687817305326\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "11 loss : 0.00020253863476682454\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "12 loss : 0.00020189504721201956\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "13 loss : 0.0002013467892538756\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "14 loss : 0.00020077472436241806\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "15 loss : 0.0002001549582928419\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "16 loss : 0.00019965440151281655\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "17 loss : 0.00019903464999515563\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "18 loss : 0.0001984864065889269\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "19 loss : 0.0001979619701160118\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "20 loss : 0.00019736604008357972\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "21 loss : 0.00019679397519212216\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "22 loss : 0.00019624573178589344\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "23 loss : 0.00019572130986489356\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "24 loss : 0.00019512537983246148\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "25 loss : 0.00019462480850052088\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "26 loss : 0.00019407656509429216\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "27 loss : 0.00019355214317329228\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "28 loss : 0.00019298007828183472\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "29 loss : 0.00019243182032369077\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "30 loss : 0.00019193123443983495\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "31 loss : 0.00019140681251883507\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "32 loss : 0.00019081089703831822\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "33 loss : 0.00019031032570637763\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "34 loss : 0.00018978590378537774\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "35 loss : 0.00018926148186437786\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "36 loss : 0.0001887132239062339\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "37 loss : 0.0001882365031633526\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "38 loss : 0.00018768824520520866\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "39 loss : 0.0001872114953584969\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "40 loss : 0.0001867109240265563\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "41 loss : 0.00018618650210555643\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "42 loss : 0.00018566209473647177\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "43 loss : 0.00018516149430070072\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "44 loss : 0.00018463707237970084\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "45 loss : 0.0001841603370849043\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "46 loss : 0.0001836597512010485\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "47 loss : 0.0001831591798691079\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "48 loss : 0.00018261090735904872\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "49 loss : 0.00018211033602710813\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "50 loss : 0.00018165743676945567\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "51 loss : 0.00018120452295988798\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "52 loss : 0.0001806801010388881\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "53 loss : 0.00018020335119217634\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "54 loss : 0.0001797504664864391\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "55 loss : 0.00017922601546160877\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "56 loss : 0.00017879695224110037\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "57 loss : 0.00017829638090915978\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "58 loss : 0.00017779579502530396\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "59 loss : 0.00017729520914144814\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "60 loss : 0.00017684229533188045\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "61 loss : 0.00017641321755945683\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "62 loss : 0.00017593646771274507\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "63 loss : 0.00017550738994032145\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "64 loss : 0.00017500680405646563\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "65 loss : 0.00017455389024689794\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "66 loss : 0.00017410097643733025\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "67 loss : 0.00017362424114253372\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "68 loss : 0.00017314749129582196\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "69 loss : 0.0001726945920381695\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "70 loss : 0.00017224166367668658\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "71 loss : 0.00017181257135234773\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "72 loss : 0.00017131201457232237\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "73 loss : 0.00017093060887418687\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "74 loss : 0.0001704538444755599\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "75 loss : 0.0001700247812550515\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "76 loss : 0.0001695718674454838\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "77 loss : 0.00016911895363591611\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "78 loss : 0.00016868986131157726\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "79 loss : 0.000168308470165357\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "80 loss : 0.00016780788428150117\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "81 loss : 0.00016737880650907755\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "82 loss : 0.00016694972873665392\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "83 loss : 0.00016654448700137436\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "84 loss : 0.00016609157319180667\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "85 loss : 0.00016566248086746782\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "86 loss : 0.00016523341764695942\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "87 loss : 0.00016480432532262057\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "88 loss : 0.00016437526210211217\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "89 loss : 0.00016397002036683261\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "90 loss : 0.00016361245070584118\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "91 loss : 0.0001631595368962735\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "92 loss : 0.00016275429516099393\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "93 loss : 0.00016234905342571437\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "94 loss : 0.00016191996110137552\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "95 loss : 0.00016151471936609596\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "96 loss : 0.0001611094776308164\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "97 loss : 0.000160680414410308\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "98 loss : 0.0001602990087121725\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n",
      "99 loss : 0.00015986991638783365\n",
      "prediction : [[4 4 3 2 0]]\n",
      "true Y : [[4, 4, 3, 2, 0]]\n",
      " prediction str : pple!\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X)\n",
    "    # view를 하는 이유는 Batch 차원 제거를 위함.\n",
    "    loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n",
    "    loss.backward() # 기울기 계산\n",
    "    optimizer.step() # 아까 optimizer 선언 시 넣어둔 파라미터 업데이트\n",
    "\n",
    "    # 아래 세 줄은 모델이 실제 어떻게 예측했는지를 확인하는 코드.\n",
    "    result = outputs.data.numpy().argmax(axis=2) # 최종 예측값인 각 time-step 별 5차원 벡터에 대해서 가장 높은 값의 인덱스를 선택\n",
    "\n",
    "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)])\n",
    "\n",
    "    print(i, f'loss : {loss.item()}\\nprediction : {result}\\ntrue Y : {y_data}\\n prediction str : {result_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 더 많은 데이터로 학습한 문자 단위 RNN(Char RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 훈련 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합을 생성하고, 각 문자에 고유한 정수를 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence)) # 중복을 제거한 문자 집합 생성\n",
    "char_dic = {c : i for i, c in enumerate(char_set)} # 각 문자에 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, 'i': 1, 'u': 2, 's': 3, 'm': 4, 'r': 5, 'd': 6, 'p': 7, 'o': 8, ' ': 9, 'w': 10, 't': 11, '.': 12, 'f': 13, 'n': 14, \"'\": 15, 'h': 16, 'y': 17, 'e': 18, 'g': 19, 'b': 20, 'k': 21, 'a': 22, 'c': 23, 'l': 24}\n"
     ]
    }
   ],
   "source": [
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문자에 정수가 부여되었으며, 총 25개의 문자가 존재한다.  \n",
    "문자 집합의 크기를 확인해보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 25\n"
     ]
    }
   ],
   "source": [
    "dic_size = len(char_dic)\n",
    "print(f'문자 집합의 크기 : {dic_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합의 크기는 25이며,  \n",
    "입력은 원-핫 벡터로 사용할 것이므로 매 시점마다 들어갈 입력의 크기이기도 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 하이퍼파라미터를 설정하자.  \n",
    "hidden_size(은닉 상태의 크기)를 입력의 크기와 동일하게 줬는데,  \n",
    "이는 사용자의 선택으로 다른 값을 줘도 무방하다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 sequence_length라는 변수를 선언했는데,  \n",
    "우리가 앞서 만든 샘플을 10개 단위로 끊어서 샘플을 만들 예정이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "hidden_size = dic_size\n",
    "sequence_length = 10   # 임의 숫자 지정\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 임의로 지정한 sequence_length 값인 10의 단위로 샘플들을 잘라서 데이터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    print(i, x_str, '->', y_str)\n",
    "\n",
    "    x_data.append([char_dic[c] for c in x_str])\n",
    "    y_data.append([char_dic[c] for c in y_str])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
