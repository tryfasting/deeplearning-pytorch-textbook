{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때, 어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 계산을 통하여 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 인공 신경망의 이해(Neural Network Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제에 사용될 인공 신경망의 구조를 살펴보자.  \n",
    "입력층, 은닉층, 출력층 이렇게 3개의 층을 갖는다.  \n",
    "\n",
    "또한 2개의 입력, 2개의 은닉층 뉴런, 2개의 출력층 뉴런을 사용한다.  \n",
    "\n",
    "은닉층과 출력층의 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층과 출력층의 모든 뉴런에서의 변수 z는,  \n",
    "이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미한다.  \n",
    "\n",
    "이 값은 아직 뉴런에서 시그모이드 함수를 거치지 않은 상태이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z 우측의 |를 지나서 존재하는 변수 h 또는 o가 바로 시그모이드 함수를 지난 후의 값이다.  \n",
    "이는 각 뉴런의 출력값을 의미한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 W에 대해서   \n",
    "역전파를 통해 업데이트하는 것을 목표로 한다.  \n",
    "편향 b는 여기서 고려하지 않는다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 순전파(Forward Propagation)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
