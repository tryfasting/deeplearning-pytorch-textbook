{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 초기 인공 신경망, 퍼셉트론에 대해서 이해한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 퍼셉트론(Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인간의 뉴런과 비슷한 구조.  \n",
    "각각의 인공 뉴런에서 보내진 입력값 x는 각각의 가중치 W와 함께 인공 뉴런에 전달.  \n",
    "가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미한다.  \n",
    "(입력값 * 가중치의 곱의 전체 합)이 threshold를 넘으면 출력 신호로 1을 출력,  \n",
    "그렇지 않으면 0을 출력.  \n",
    "이러한 함수를 계단 함수라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계단 함수에 사용된 임계치 값을 수식으로는 보통 Θ(theta)로 표현한다.  \n",
    "단, 임계치를 좌변으로 넘겨서 편향 b(bias)로 표현할 수도 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 인공 신경망 자료에서 편의상 편향 b가 생략되기도 하나  \n",
    "실제로는 편향 b 또한 딥러닝이 최적의 값을 찾아야 할 변수 중 하나이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같이 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)이라고 한다.  \n",
    "시그모이드, 소프트맥스 함수 또한 활성화 함수 중 하나이다.  \n",
    "\n",
    "퍼셉트론 이전에 로지스틱 회귀를 배운 까닭도 여기에 있다.  \n",
    "퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면  \n",
    "방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 단층 퍼셉트론(Single-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 단층 그리고 다층 퍼셉트론으로 나뉜다.  \n",
    "단층 퍼셉트론은 값을 보내는 단계, 값을 받아서 출력하는 두 단계로만 이루어진다.  \n",
    "각 단계를 층(layer)라고 부르며,  \n",
    "이 두 개의 층을 입력층(input layer), 출력층(output layer)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단층 퍼셉트론이 어떤 일을 할 수 있는지,  \n",
    "한계는 무엇인지 배워보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있다.  \n",
    "파이썬 코드로 간단하게 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, x2 값이 모두 1일 경우에만 return 1\n",
    "def AND_gate(x1,x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = - 0.7 # -1보다 크게 , - 0.5보다 낮게 설정하면 된다.\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND_gate의 가중치와 편향에 -하면 된다.\n",
    "def NAND_gate(x1,x2):\n",
    "    w1= -0.5\n",
    "    w2= -0.5\n",
    "    b = 0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate(x1,x2):\n",
    "    w1 = 0.6\n",
    "    w2 = 0.6 # w1, w2 모두 0.5보다 크게 하면 된다.\n",
    "    b = -0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단층 퍼셉트론으로는 XOR 게이트를 구현하기 불가능하다.  \n",
    "자세한 이유는 링크의 그림 참조.  \n",
    "https://wikidocs.net/60680"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다층 퍼셉트론(MultiLayer Perceptron, MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 게이트는, 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있다.  \n",
    "퍼셉트론 관점에서 말하자면, 층을 더 쌓으면 된다는 것이다.  \n",
    "\n",
    "다층 퍼셉트론은 중간에 층을 더 추가했다는 점에서 다르다.  \n",
    "이렇게 입력층, 출력층 사이에 존재하는 층을 은닉층(hidden layer)라고 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_gate(x1,x2):\n",
    "    return NAND_gate(x1,x2) * OR_gate(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR_gate(0,0) , XOR_gate(1,0), XOR_gate(0,1), XOR_gate(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
