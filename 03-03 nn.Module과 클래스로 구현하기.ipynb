{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 파이토치에서 이미 구현된 함수들을 불러와서 더 쉽게 선형 회귀 모델을 구현해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 단순 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22a2a27ae50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 1, output_dim = 1\n",
    "# 하나의 입력 x, 하나의 출력 y이므로, 모두 1을 넣었다.\n",
    "model = nn.Linear(1,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4694], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# model에 저장되어 있는 가중치 W와 편향 b\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 설정. 경사하강법 SGD를 사용하고 learning rate는 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 14.714844\n",
      "Epoch  100/2000 Cost: 0.127436\n",
      "Epoch  200/2000 Cost: 0.078748\n",
      "Epoch  300/2000 Cost: 0.048661\n",
      "Epoch  400/2000 Cost: 0.030070\n",
      "Epoch  500/2000 Cost: 0.018581\n",
      "Epoch  600/2000 Cost: 0.011482\n",
      "Epoch  700/2000 Cost: 0.007095\n",
      "Epoch  800/2000 Cost: 0.004384\n",
      "Epoch  900/2000 Cost: 0.002709\n",
      "Epoch 1000/2000 Cost: 0.001674\n",
      "Epoch 1100/2000 Cost: 0.001035\n",
      "Epoch 1200/2000 Cost: 0.000639\n",
      "Epoch 1300/2000 Cost: 0.000395\n",
      "Epoch 1400/2000 Cost: 0.000244\n",
      "Epoch 1500/2000 Cost: 0.000151\n",
      "Epoch 1600/2000 Cost: 0.000093\n",
      "Epoch 1700/2000 Cost: 0.000058\n",
      "Epoch 1800/2000 Cost: 0.000036\n",
      "Epoch 1900/2000 Cost: 0.000022\n",
      "Epoch 2000/2000 Cost: 0.000014\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련 데이터에 대해 경사하강법을 2,000회 반복\n",
    "nb_epochs = 2000\n",
    "for epoch in range(np_epochs+1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    # pytorch에서 제공하는 평균제곱오차 함수\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    # 비용함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()    \n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9926]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 4 선언\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "\n",
    "# 입력할 값 4에 대해서 예측값 y^를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)\n",
    "\n",
    "print(f'훈련 후 입력이 4일 때의 예측값 : {pred_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W의 값이 2에 가깝고, b의 값이 0에 가까운 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.9957]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0097], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H(x) 식에 입력 x로부터 예측된 y를 얻는 것을 forward 연산이라고 한다.\n",
    "- 학습 전, prediction = model(x_train)은 x_train으로부터 예측값을 리턴하므로 forward연산\n",
    "- 학습 후, pred_y = model(new_var)는 임의의 값 new_var로부터 예측값을 리턴하므로 forward연산\n",
    "\n",
    "- cost.backward()는 비용 함수로부터 기울기를 구하라는 의미이며 backward 연산이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다중 선형 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25a080a8950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 다중 선형 회귀이므로 input_dim = 3, output_dim = 1\n",
    "        self.linear = nn.Linear(3,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/5000 Cost: 0.199759\n",
      "Epoch  100/5000 Cost: 0.198940\n",
      "Epoch  200/5000 Cost: 0.198153\n",
      "Epoch  300/5000 Cost: 0.197401\n",
      "Epoch  400/5000 Cost: 0.196682\n",
      "Epoch  500/5000 Cost: 0.195994\n",
      "Epoch  600/5000 Cost: 0.195332\n",
      "Epoch  700/5000 Cost: 0.194707\n",
      "Epoch  800/5000 Cost: 0.194104\n",
      "Epoch  900/5000 Cost: 0.193534\n",
      "Epoch 1000/5000 Cost: 0.192977\n",
      "Epoch 1100/5000 Cost: 0.192451\n",
      "Epoch 1200/5000 Cost: 0.191935\n",
      "Epoch 1300/5000 Cost: 0.191453\n",
      "Epoch 1400/5000 Cost: 0.190981\n",
      "Epoch 1500/5000 Cost: 0.190538\n",
      "Epoch 1600/5000 Cost: 0.190106\n",
      "Epoch 1700/5000 Cost: 0.189695\n",
      "Epoch 1800/5000 Cost: 0.189290\n",
      "Epoch 1900/5000 Cost: 0.188907\n",
      "Epoch 2000/5000 Cost: 0.188537\n",
      "Epoch 2100/5000 Cost: 0.188181\n",
      "Epoch 2200/5000 Cost: 0.187843\n",
      "Epoch 2300/5000 Cost: 0.187511\n",
      "Epoch 2400/5000 Cost: 0.187188\n",
      "Epoch 2500/5000 Cost: 0.186886\n",
      "Epoch 2600/5000 Cost: 0.186588\n",
      "Epoch 2700/5000 Cost: 0.186300\n",
      "Epoch 2800/5000 Cost: 0.186021\n",
      "Epoch 2900/5000 Cost: 0.185753\n",
      "Epoch 3000/5000 Cost: 0.185489\n",
      "Epoch 3100/5000 Cost: 0.185239\n",
      "Epoch 3200/5000 Cost: 0.184994\n",
      "Epoch 3300/5000 Cost: 0.184753\n",
      "Epoch 3400/5000 Cost: 0.184524\n",
      "Epoch 3500/5000 Cost: 0.184304\n",
      "Epoch 3600/5000 Cost: 0.184088\n",
      "Epoch 3700/5000 Cost: 0.183877\n",
      "Epoch 3800/5000 Cost: 0.183670\n",
      "Epoch 3900/5000 Cost: 0.183469\n",
      "Epoch 4000/5000 Cost: 0.183270\n",
      "Epoch 4100/5000 Cost: 0.183085\n",
      "Epoch 4200/5000 Cost: 0.182897\n",
      "Epoch 4300/5000 Cost: 0.182719\n",
      "Epoch 4400/5000 Cost: 0.182537\n",
      "Epoch 4500/5000 Cost: 0.182369\n",
      "Epoch 4600/5000 Cost: 0.182203\n",
      "Epoch 4700/5000 Cost: 0.182031\n",
      "Epoch 4800/5000 Cost: 0.181868\n",
      "Epoch 4900/5000 Cost: 0.181714\n",
      "Epoch 5000/5000 Cost: 0.181561\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    # pytorch에서 제공하는 평균제곱오차 함수\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 비용함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()    \n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
