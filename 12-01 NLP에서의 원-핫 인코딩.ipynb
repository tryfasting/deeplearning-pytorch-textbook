{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tryfasting/deeplearning-pytorch-textbook/blob/main/12-01%20NLP%EC%97%90%EC%84%9C%EC%9D%98%20%EC%9B%90-%ED%95%AB%20%EC%9D%B8%EC%BD%94%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvgFGFx-EFCl"
      },
      "source": [
        "단어 집합이란 서로 다른 단어들의 집합이다.    \n",
        "book, books를 다른 단어로 간주한다.  \n",
        "\n",
        "원-핫 인코딩을 위해서는,  \n",
        "1. 단어 집합을 만든다.  \n",
        "2. 정수 인코딩을 한다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czugCPXhEFCm"
      },
      "source": [
        "### 1. 원-핫 인코딩(One-hot encoding)이란?\n",
        "\n",
        "원-핫 인코딩 실습을 해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v8kIzBE-EFCn",
        "outputId": "b618beed-7afd-4a07-8189-1e9d3df6d72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.2 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "import konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xhZua5thEFCn",
        "outputId": "8130cb07-70a8-4451-afcf-c731cd73ebec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다', '.']\n"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "token = okt.morphs('나는 자연어 처리를 배운다.')\n",
        "print(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화한 인덱스에 정수 인덱스를 부여했다.(정수 인코딩)"
      ],
      "metadata": {
        "id": "S9j-WWcgEv3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2index = {}\n",
        "for voca in token:\n",
        "  if voca not in word2index.keys():\n",
        "    word2index[voca] = len(word2index)\n",
        "\n",
        "print(word2index)"
      ],
      "metadata": {
        "id": "Y6KqFB0jEhFU",
        "outputId": "ebe896ac-2ff3-4654-e948-dff7ab7abcbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5, '.': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰을 입력하면 해당 토큰에 정수 인덱스를 매핑해서 원-핫 벡터를 만들어내는 함수를 만들자."
      ],
      "metadata": {
        "id": "JzTN5p7mFREl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word, word2index):\n",
        "  one_hot_vector = [0] * (len(word2index))\n",
        "  index = word2index[word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector"
      ],
      "metadata": {
        "id": "0innpmP3E3m0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'자연어'라는 토큰을 입력했더니 [0,0,1,0,0,0] 이라는 벡터가 나왔다. 자연어는 단어 집합에서 인덱스가 2이므로, 자연어를 표현하는 원-핫 벡터는 인덱스 2의 값이 1이며, 나머지 값은 0인 벡터이다."
      ],
      "metadata": {
        "id": "lUw22D07Fvss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding('자연어',word2index)"
      ],
      "metadata": {
        "id": "9sW9mBhgFp4o",
        "outputId": "0294274f-bf78-4519-af39-5f279f351d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 원-핫 인코딩(One-hot encoding)의 한계"
      ],
      "metadata": {
        "id": "Di965gHgGPnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 필요한 공간이 계속 늘어난다. 단어가 1000개인 코퍼스를 가지고 원-핫 벡터를 만들면, 모든 단어 각각 1000개의 차원을 갖는 벡터가 된다는 것이다.\n",
        "\n",
        "2. `단어`의 유사도를 표현하지 못한다. 늑대, 호랑이, 강아지, 고양이에 대해서 유사한지 알 수 없다. 검색 시스템 등에서 심각한 문제가 된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "p1tyU2qOGVDc"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}