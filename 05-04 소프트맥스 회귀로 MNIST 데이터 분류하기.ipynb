{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터에 대해 이해하고, 파이토치로 소프트맥스 회귀를 구현하기 MNIST 데이터를 분류해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MNIST 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0부터 9까지의 이미지로 이루어진 손글씨 데이터셋이다.  \n",
    "60,000개의 훈련 데이터와 레이블,  \n",
    "총 10,000개의 테스트 데이터와 레이블로 구성되어 있다.  \n",
    "레이블은 0-9까지 총 10개.  \n",
    "한 이미지당 28 * 28 픽셀."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 토치비전(torchvision) 소개하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함  \n",
    "자연어 처리를 위해서는 토치텍스트라는 패키지가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 분류기 구현을 위한 사전 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다 : cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(f'다음 기기로 학습합니다 : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MNIST 분류기 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.datasets.dsets.MNIST를 사용하여 MNIST 데이터셋을 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST dataset\n",
    "\n",
    "# transform= : 파이토치 텐서로 바꿔준다.\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = DataLoader(dataset=mnist_train,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "# shuffle : 매 에포크마다 미니 배치를 셔플할 것인지 설정\n",
    "# drop_last : 마지막 배치를 버릴 것인지 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop_last를 하는 이유\n",
    "1000개의 데이터, 배치 크기 128이라고 해보자.  \n",
    "1000을 128로 나누면 나머지가 104가 남는다.  \n",
    "\n",
    "데이터가 충분한 상황이라면,     \n",
    "다른 미니배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여     \n",
    "마지막 배치가 상대적으로 과대 평가되는 현상을 막아준다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "딥러닝에서 미니 배치 크기는 모델의 성능과 학습 과정에 중요한 영향을 미칩니다.  \n",
    "미니 배치 크기에 따른 주요 영향은 다음과 같습니다:\n",
    "\n",
    "1. 학습 속도:\n",
    "\n",
    "큰 배치 크기: 한 번에 더 많은 데이터를 처리하므로 학습 속도가 빨라집니다.  \n",
    "작은 배치 크기: 더 자주 모델을 업데이트하지만, 전체적인 학습 시간이 늘어날 수 있습니다.\n",
    "\n",
    "2. 메모리 사용:\n",
    "\n",
    "큰 배치 크기: 더 많은 메모리를 필요로 합니다.  \n",
    "작은 배치 크기: 메모리 요구량이 줄어듭니다.\n",
    "\n",
    "3. 일반화 성능:\n",
    "\n",
    "큰 배치 크기: 과적합 위험이 증가할 수 있습니다.  \n",
    "작은 배치 크기: 데이터의 노이즈로 인해 일반화 성능이 향상될 수 있습니다.  \n",
    "\n",
    "4. 최적화 안정성:\n",
    "\n",
    "작은 배치 크기: 학습 과정이 불안정할 수 있지만, 지역 최솟값을 벗어나는 데 도움이 될 수 있습니다.  \n",
    "큰 배치 크기: 학습이 더 안정적이지만, 지역 최솟값에 빠질 위험이 있습니다.\n",
    "\n",
    "5. 하드웨어 효율성:\n",
    "\n",
    "큰 배치 크기: GPU와 같은 병렬 처리 하드웨어를 더 효율적으로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "이제 모델을 설계한다. input_dim 784, output_dim은 10이다.  \n",
    "bias는 편향 b를 사용할 것인지를 나타낸다. 기본값은 True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to() 메소드는 연산을 어디서 수행할지를 정한다.  \n",
    "모델의 매개변수를 지정한 장치의 메모리로 보낸다.  \n",
    "GPU를 사용하려면 to('cuda')를 해 줄 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150647\n",
      "Epoch: 0002 cost = 0.359577775\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404670\n",
      "Epoch: 0005 cost = 0.307107002\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956199\n",
      "Epoch: 0009 cost = 0.287074119\n",
      "Epoch: 0010 cost = 0.284515619\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526860\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874794\n",
      "Epoch: 0015 cost = 0.274422795\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# 앞서 training_epochs의 값은 15로 지정함\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X,Y in data_loader:\n",
    "        # hyperparameter 설정 셀에서 ,배치 크기를 100으로 설정했으므로, \n",
    "        # 아래의 연산에서 X는 (100,784) 텐서가 된다.\n",
    "        X = X.view(-1,28*28).to(device)\n",
    "\n",
    "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0~9의 정수.\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델을 테스트 데이터로 평가하고,   \n",
    "테스트 데이터에서 임의의 이미지를 선택하여 모델이 해당 이미지를 어떻게 예측하는지  \n",
    "시각적으로 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8883000016212463\n",
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
    "\n",
    "# torch.no_grad() : gradient 계산을 수행하지 않는다.\n",
    "with torch.no_grad():\n",
    "    # .view(-1,28*28)은 flatten 효과를 갖는다.\n",
    "    X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, dim=1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다.\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r+1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys',interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".view(-1,28*28)가 flatten 효과를 갖는 이유.  \n",
    "  \n",
    "원본 이미지의 구조는 torch.Size([10000, 28, 28])의 구조였다.  \n",
    "이를 view 메소드로 바꿔주면, torch.Size([10000,28*28])의 형태가 된다.  \n",
    "즉, 2차원 행렬 10000개를 1차원 벡터 10000개로 바꿔준것이다.  \n",
    "2개의 축을 가진 2차원 데이터를 1차원으로 길게 늘어뜨렸으므로, flatten  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Workspace\\deeplearning-pytorch-textbook\\.venv\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "print(mnist_test.test_data.shape)\n",
    "print(mnist_test.test_data.view(-1,28*28).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".argmax 메소드는 텐서에서 가장 큰 값의 인덱스를 반환한다.  \n",
    "dim을 지정하면, 행방향, 혹은 열방향으로 가장 큰 값을 찾아준다.  \n",
    "prediction의 경우 torch.Size([10000,10])이다.  \n",
    "10000개의 이미지에 대한, 10개의 클래스에 대한 예측값이 있다.  \n",
    "즉, 행방향(dim=1)로 가장 큰 값의 인덱스를 모두 반환해준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  218.3591, -2471.1321,   346.5565,  1417.3794,  -767.6719,  -352.6882,\n",
      "        -2070.1768,  2475.0425,   393.8430,   791.0422])\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])\n",
    "print(torch.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_test는 실제 정답 레이블을 담고 있는 원-핫 벡터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[0])\n",
    "print(mnist_test.test_labels)\n",
    "print(mnist_test.test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct_prediction은 정답을 맞추었는지 틀렸는지 담고 있는 텐서이다.  \n",
    "해당 텐서의 shape는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Workspace\\deeplearning-pytorch-textbook\\.venv\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "print(mnist_test.test_data[r:r+1].shape)\n",
    "print(mnist_test.test_data[r:r+1].view(-1,28*28).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".item() 메소드는 다음과 같이 python number로 return해준다.\n",
    "Returns the value of this tensor as a standard Python number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(Y_single_data)\n",
    "print(Y_single_data.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
